{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели и подсчет метрик\n",
    "\n",
    "### Выбор модели и аргументы в пользу неё\n",
    "\n",
    "Поскольку наша задача выдления основных трендов и тем, я полагаю, что использование ``Bertopic`` является подходящим решением, поскольку\n",
    "\n",
    "- Он использует современные языковые модели для получения контекстуальных эмбеддингов, что важно для специализированных текстов.\n",
    "\n",
    "- Кластеризация с ``HDBSCAN`` эффективно отделяет релевантные темы от шума.\n",
    "\n",
    "- Автоматическое извлечение ключевых слов с помощью ``TF-IDF`` позволяет формировать интерпретируемые названия тем.\n",
    "\n",
    "- Возможность интегрировать временной анализ помогает визуализировать динамику трендов по месяцам.\n",
    "\n",
    "\n",
    "### Каким образом работает модель\n",
    "\n",
    "Общая интиуция тематического моделирования с помощью ``Bertopic``:\n",
    "\n",
    "1. **Предобработка данных**: выбор текстов для тематического моделирования, препроцесим тексты (удалеям стоп слова, чистим http сылки и тп), но важно, что преобразование в эмбединги идет без удаления стоп слов \n",
    "\n",
    "2. **Получение эмбеддингов**: с помощью энкодера получаем векторное представление текстов\n",
    "\n",
    "3. **Снижение размерности**: С помощью umap, мы снижаем размерность для кластеризации, чтобы минимизировать проклятие размерности, используем umap, а не pca, поскольку эмбединги нелинейные\n",
    "\n",
    "3. **Кластеризация**: Применяем алгоритм кластеризации, в нашем случае ``HDBSCAN``, поскольку как я говорил ранее нам хотелось бы отделить шумовые кластеры\n",
    "\n",
    "4. **Получение названий топиков**: Для каждого кластера автоматически извлекаем ключевые слова с помощью TF-IDF\n",
    "\n",
    "5. **Оцениваем качество модели**: Используем метрки качетсва кластеризации, а также топиков.\n",
    "\n",
    "\n",
    "## Технические особенности\n",
    "\n",
    "Из коробки ``Bertopic`` работает на CPU, поэтому я использовал приприетарную библиотеку Nvidia ``cuml`` для переноса вычисления на гпу, также препроцесинг текстов реализован многопоточно с помощью библиотеки ``pandarallel``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступно GPU: 1\n",
      "Название GPU: NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from numba import cuda\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import bertopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from cuml.cluster import HDBSCAN\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.cluster import HDBSCAN\n",
    "import os\n",
    "from pandarallel import pandarallel\n",
    "import spacy\n",
    "from utils import check_gpu\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "tqdm.pandas()\n",
    "check_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загрузим данные из ноутбука ``2_data_observation.ipynb``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "      <th>year</th>\n",
       "      <th>categories</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>arxiv_url</th>\n",
       "      <th>doi</th>\n",
       "      <th>comment</th>\n",
       "      <th>journal_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>http://arxiv.org/abs/2409.07236v2</td>\n",
       "      <td>2409.07236v2</td>\n",
       "      <td>3DGCQA: A Quality Assessment Database for 3D A...</td>\n",
       "      <td>Yingjie Zhou, Zicheng Zhang, Farong Wen, Jun J...</td>\n",
       "      <td>Although 3D generated content (3DGC) offers ad...</td>\n",
       "      <td>2024-09-11</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>2024</td>\n",
       "      <td>eess.IV, cs.CV</td>\n",
       "      <td>eess.IV</td>\n",
       "      <td>http://arxiv.org/pdf/2409.07236v2</td>\n",
       "      <td>http://arxiv.org/abs/2409.07236v2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               entry_id      arxiv_id  \\\n",
       "2518  http://arxiv.org/abs/2409.07236v2  2409.07236v2   \n",
       "\n",
       "                                                  title  \\\n",
       "2518  3DGCQA: A Quality Assessment Database for 3D A...   \n",
       "\n",
       "                                                authors  \\\n",
       "2518  Yingjie Zhou, Zicheng Zhang, Farong Wen, Jun J...   \n",
       "\n",
       "                                               abstract   published  \\\n",
       "2518  Although 3D generated content (3DGC) offers ad...  2024-09-11   \n",
       "\n",
       "         updated  year      categories primary_category  \\\n",
       "2518  2024-09-12  2024  eess.IV, cs.CV          eess.IV   \n",
       "\n",
       "                                pdf_url                          arxiv_url  \\\n",
       "2518  http://arxiv.org/pdf/2409.07236v2  http://arxiv.org/abs/2409.07236v2   \n",
       "\n",
       "      doi comment journal_ref  \n",
       "2518  NaN     NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/video_generation_2024.csv')\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "\n",
    "Я заметил, что в abstract большое количество ссылок, которые будут зашумлять данные, давайте их почистим, хотя для современных энкодеров препроцессинг особо не нужен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove links from the abstracts\n",
    "df['abstract'] = df['abstract'].apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+', '', x, flags=re.MULTILINE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также я полагаю эффективным использование такой фичи как название статьи + abstract, пскольку это даст больше информации модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column with title and abstract to use for clustering\n",
    "df['title_abstract'] = df['title'] + ' ' + df['abstract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Энкодер я выбрал ``all-MiniLM-L6-v2``, поскольку он относительно легковесный для моей Видеокарты и является отчасти отрослевым бейзлайном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1316ba59f2b430c9e2cc7270e8d946b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedding_model.encode(df.title_abstract.to_list(), show_progress_bar=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Препроцессинг для получение названий топиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также я решил лематизировать тексты, поскольку из коробки ``tf-idf`` бертопика работает не очень хорошо, давайте упростим себе и ему задачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e82d74d9a344a54a8f4de8c9f63a41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=865), Label(value='0 / 865'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lemmatize(text):\n",
    "    if not hasattr(lemmatize, \"nlp\"):\n",
    "        lemmatize.nlp = spacy.load(\"en_core_web_lg\", disable=[\"parser\", \"ner\"])\n",
    "        \n",
    "    doc = lemmatize.nlp(text)\n",
    "    return \" \".join(token.lemma_ for token in doc if not token.is_punct and not token.is_space)\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)\n",
    "\n",
    "df['title_abstract_lem'] = df['title_abstract'].parallel_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо этого я решил убрать стоп слова и добавить в них стоп слова, которые характерны для научных статей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kiril/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "standard_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "scientific_stop_words = set([\n",
    "    'introduction', 'conclusion', 'method', 'methods', 'result', 'results',\n",
    "    'discussion', 'paper', 'article', 'journal', 'figure', 'fig', 'table',\n",
    "    'author', 'study', 'studies', 'analysis', 'data', 'based', 'using', 'used',\n",
    "    'show', 'shown', 'propose', 'proposed', 'approach', 'demonstrate', 'demonstrated',\n",
    "    'experiment', 'experimental', 'conclude', 'research', 'review', 'literature',\n",
    "    'abstract', 'keywords', 'acknowledgement', 'model', 'models', 'methodology',\n",
    "    'performance', 'related', 'work', 'previous', 'recent', 'technique',\n",
    "    'system', 'systems', 'evaluate', 'evaluated', 'evaluation', 'state', 'art',\n",
    "    'significant', 'contribution', 'contributions', 'novel', 'effective', 'effectively'\n",
    "])\n",
    "\n",
    "final_stop_words = standard_stop_words.union(scientific_stop_words)\n",
    "\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=list(final_stop_words), \n",
    "    max_df=0.8,\n",
    "    min_df=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Снижение размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-02 02:46:32.495] [CUML] [info] build_algo set to brute_force_knn because random_state is given\n"
     ]
    }
   ],
   "source": [
    "umap_model = UMAP(\n",
    "    n_components=15,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.05,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=25,\n",
    "    min_samples=8,\n",
    "    metric='euclidean',\n",
    "    cluster_selection_method='eom',\n",
    "    prediction_data=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование модели bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_model = bertopic.BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    verbose=True,\n",
    "    calculate_probabilities=True,\n",
    "    top_n_words=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 02:46:32,571 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-04-02 02:46:33,253 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-04-02 02:46:33,254 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-04-02 02:46:33,560 - BERTopic - Cluster - Completed ✓\n",
      "2025-04-02 02:46:33,563 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-04-02 02:46:33,921 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обнаружено кластеров: 35\n",
      "Информация о кластерах:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2132</td>\n",
       "      <td>-1_scene_camera_action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1364</td>\n",
       "      <td>0_segmentation_medical_mri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "      <td>1_editing_edit_t2v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>414</td>\n",
       "      <td>2_robot_policy_manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>202</td>\n",
       "      <td>3_facial_head_talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>4_gaussian_scene_splatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>169</td>\n",
       "      <td>5_deepfake_attack_adversarial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>152</td>\n",
       "      <td>6_super_resolution_sr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>7_traffic_forecasting_graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "      <td>8_quantum_vortex_wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>107</td>\n",
       "      <td>9_compression_codec_coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>106</td>\n",
       "      <td>10_question_reasoning_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>11_audio_sound_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>104</td>\n",
       "      <td>12_caption_captioning_retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>13_hyperspectral_spectral_hsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>14_action_vocabulary_activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "      <td>15_character_synthesis_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>16_sar_radar_imagery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>73</td>\n",
       "      <td>17_surgical_surgery_sam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>18_tracking_segmentation_vos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>19_driving_autonomous_traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>20_assessment_vqa_iqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>21_monocular_scene_estimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>22_egocentric_grasp_ego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>23_recommendation_social_creator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>46</td>\n",
       "      <td>24_llm_geospatial_student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "      <td>25_anomaly_vad_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>26_token_tokenizer_tokenization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>27_emotion_expression_facial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>28_sign_gloss_translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>29_communication_wireless_transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>30_game_player_llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31_pulsar_star_gravitational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>32_estimation_occlusion_infant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>33_rppg_physiological_remote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                    Name\n",
       "0      -1   2132                  -1_scene_camera_action\n",
       "1       0   1364              0_segmentation_medical_mri\n",
       "2       1    517                      1_editing_edit_t2v\n",
       "3       2    414             2_robot_policy_manipulation\n",
       "4       3    202                      3_facial_head_talk\n",
       "5       4    197              4_gaussian_scene_splatting\n",
       "6       5    169           5_deepfake_attack_adversarial\n",
       "7       6    152                   6_super_resolution_sr\n",
       "8       7    129             7_traffic_forecasting_graph\n",
       "9       8    110                   8_quantum_vortex_wave\n",
       "10      9    107              9_compression_codec_coding\n",
       "11     10    106            10_question_reasoning_answer\n",
       "12     11    105                    11_audio_sound_music\n",
       "13     12    104         12_caption_captioning_retrieval\n",
       "14     13     77           13_hyperspectral_spectral_hsi\n",
       "15     14     77           14_action_vocabulary_activity\n",
       "16     15     74             15_character_synthesis_body\n",
       "17     16     74                    16_sar_radar_imagery\n",
       "18     17     73                 17_surgical_surgery_sam\n",
       "19     18     72            18_tracking_segmentation_vos\n",
       "20     19     64           19_driving_autonomous_traffic\n",
       "21     20     64                   20_assessment_vqa_iqa\n",
       "22     21     60           21_monocular_scene_estimation\n",
       "23     22     54                 22_egocentric_grasp_ego\n",
       "24     23     53        23_recommendation_social_creator\n",
       "25     24     46               24_llm_geospatial_student\n",
       "26     25     46                   25_anomaly_vad_normal\n",
       "27     26     43         26_token_tokenizer_tokenization\n",
       "28     27     41            27_emotion_expression_facial\n",
       "29     28     38               28_sign_gloss_translation\n",
       "30     29     37  29_communication_wireless_transmission\n",
       "31     30     32                      30_game_player_llm\n",
       "32     31     31            31_pulsar_star_gravitational\n",
       "33     32     26          32_estimation_occlusion_infant\n",
       "34     33     26            33_rppg_physiological_remote"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics, probs = bertopic_model.fit_transform(df.title_abstract_lem.to_list(), embeddings=embeddings)\n",
    "\n",
    "topic_info = bertopic_model.get_topic_info()\n",
    "\n",
    "print(f\"Обнаружено кластеров: {len(topic_info)}\")\n",
    "print(f\"Информация о кластерах:\")\n",
    "topic_info[['Topic', 'Count', 'Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет качества кластеризации и тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Краткая справка по метрикам: \n",
    "\n",
    "``Silhouette Score``: Оценивает разделение кластеров  (от -1 до 1, хорошие > 0.5)\n",
    "\n",
    "``c_v``: Мера семантической связности темы  (от 0 до 1, хорошие > 0.5)\n",
    "\n",
    "``c_npmi``: Нормированная точечная взаимная информация между словами  (от -1 до 1, хорошие > 0)\n",
    "\n",
    "``u_mass``: Когерентность на основе со-встречаемости  (от -∞ до 0, хорошие – ближе к 0)\n",
    "\n",
    "``c_uci``: Мера когерентности через точечную взаимную информацию (чем выше – тем лучше).\n",
    "\n",
    "``Topic Diversity``: Доля уникальных слов в топ-N тем (от 0 до 1, хорошие – ближе к 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.5397239923477173\n",
      "Coherence (c_v): 0.8210221614838007\n",
      "Coherence (c_npmi): 0.19905209113081204\n",
      "Coherence (u_mass): -2.8766630095168915\n",
      "Coherence (c_uci): 0.8559725662682557\n",
      "Topic Diversity: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cuml.metrics.cluster import silhouette_score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "import ast\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "topic_info = bertopic_model.get_topic_info() \n",
    "topic_info = topic_info[topic_info.Topic != -1]\n",
    "topic_words = topic_info['Representation'].tolist()\n",
    "topic_words = [ast.literal_eval(rep) if isinstance(rep, str) else rep for rep in topic_words]\n",
    "\n",
    "N = 3\n",
    "\n",
    "umap_embeddings = umap_model.transform(embeddings)\n",
    "\n",
    "labels = np.array(topics)\n",
    "mask = labels != -1\n",
    "\n",
    "umap_embeddings_gpu = cp.asarray(umap_embeddings[mask])\n",
    "labels_gpu = cp.asarray(labels[mask])\n",
    "\n",
    "sil_score = silhouette_score(umap_embeddings_gpu, labels_gpu, metric='cosine')\n",
    "print(\"Silhouette Score:\", sil_score)\n",
    "\n",
    "docs = [doc.split() for doc in df['title_abstract_lem']]\n",
    "\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "coherence_cv    = CoherenceModel(topics=topic_words, texts=docs, dictionary=dictionary, coherence='c_v').get_coherence()\n",
    "coherence_npmi  = CoherenceModel(topics=topic_words, texts=docs, dictionary=dictionary, coherence='c_npmi').get_coherence()\n",
    "coherence_umass = CoherenceModel(topics=topic_words, texts=docs, dictionary=dictionary, coherence='u_mass').get_coherence()\n",
    "coherence_uci   = CoherenceModel(topics=topic_words, texts=docs, dictionary=dictionary, coherence='c_uci').get_coherence()\n",
    "\n",
    "print(\"Coherence (c_v):\", coherence_cv)\n",
    "print(\"Coherence (c_npmi):\", coherence_npmi)\n",
    "print(\"Coherence (u_mass):\", coherence_umass)\n",
    "print(\"Coherence (c_uci):\", coherence_uci)\n",
    "\n",
    "\n",
    "unique_topic_words = set(word for topic in topic_words for word in topic[:N])\n",
    "topic_diversity = len(unique_topic_words) / (len(topic_words) * N)\n",
    "print(\"Topic Diversity:\", topic_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('bertopic_model', exist_ok=True)\n",
    "\n",
    "bertopic_model.save(path='bertopic_model', serialization=\"pytorch\", save_ctfidf=True, save_embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cохранеяем препроценный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/video_generation_2024_bertopic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
